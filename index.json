[{"authors":"admin","categories":null,"content":"I\u0026rsquo;m a postdoc at the Learning and Intelligence Systems Lab working with Marc Toussaint. I\u0026rsquo;m affiliated with Uni Stuttgart \u0026amp; Max Planck Institute for Intelligent Systems, and working within the Cluster of Excellence: IntCDC.\nMy research interests include task and motion planning in robotics, and learning and reasoning for intelligent systems. I received my PhD degree from TU Munich, where I focused on HRI in close-proximity scenarios. I studied computer science at UBC and Ko√ß Uni, and started my research journey working on haptic interfaces.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"I\u0026rsquo;m a postdoc at the Learning and Intelligence Systems Lab working with Marc Toussaint. I\u0026rsquo;m affiliated with Uni Stuttgart \u0026amp; Max Planck Institute for Intelligent Systems, and working within the Cluster of Excellence: IntCDC.","tags":null,"title":"","type":"authors"},{"authors":["Valentin N. Hartmann","Ozgur S. Oguz","Danny Driess","Marc Toussaint","Achim Menges"],"categories":null,"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"d16e87a66eed7ed41dfd76c30279f992","permalink":"/publication/hartmann-robust-2020/","publishdate":"2020-06-06T16:04:50.488253Z","relpermalink":"/publication/hartmann-robust-2020/","section":"publication","summary":"Integrating robotic systems in architectural and construction processes is of core interest to increase the efficiency of the building industry. Automated planning for such systems enables design analysis tools and facilitates faster design iteration cycles for designers and engineers. However, generic task-and-motion planning (TAMP) for long-horizon construction processes is beyond the capabilities of current approaches. In this paper, we develop a multi-agent TAMP framework for long horizon problems such as constructing a full-scale building. To this end we extend the Logic-Geometric Programming framework by sampling-based motion planning,a limited horizon approach, and a task-specific structural stability optimization that allow an effective decomposition of the task. We show that our framework is capable of constructing a large pavilion built from several hundred geometrically unique building elements from start to end autonomously.","tags":["myself"],"title":"Robust Task and Motion Planning for Long-Horizon Architectural Construction Planning","type":"publication"},{"authors":["Zhehua Zhou","Ozgur S. Oguz","Marion Leibold","Martin Buss"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"3f56497e34998ec44c0b3dcd421b3504","permalink":"/publication/zhou-general-2020/","publishdate":"2020-06-06T16:04:50.489193Z","relpermalink":"/publication/zhou-general-2020/","section":"publication","summary":"Although the state-of-the-art learning approaches exhibit impressive results for dynamical systems, only a few applications on real physical systems have been presented. One major impediment is that the intermediate policy during the training procedure may result in behaviors that are not only harmful to the system itself but also to the environment. In essence, imposing safety guarantees for learning algorithms is vital for autonomous systems acting in the real world. In this article, we propose a computationally effective and general safe learning framework, specifically for complex dynamical systems. With a proper definition of the safe region, a supervisory control strategy, which switches the actions applied on the system between the learning-based controller and a predefined corrective controller, is given. A simplified system facilitates the estimation of the safe region for the high-dimensional dynamical system. During the learning phase, the belief of the safe region is updated with the actual execution results of the corrective controller, which in turn enables the learning-based controller to have more freedom in choosing its actions. Two examples are given to demonstrate the performance of the proposed framework, one simple inverted pendulum to illustrate the online adaptation method, and one quadcopter control task to show the overall performance.","tags":["myself","safe_learning"],"title":"A General Framework to Increase Safety of Learning Algorithms for Dynamical Systems Based on Region of Attraction Estimation","type":"publication"},{"authors":["Danny Driess","Ozgur Oguz","Jung-Su Ha","Marc Toussaint"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"d4c56ed8da6fd4ec317f880fabf603e0","permalink":"/publication/driess-deep-2020/","publishdate":"2020-06-06T16:04:50.486088Z","relpermalink":"/publication/driess-deep-2020/","section":"publication","summary":"In this paper, we propose a deep neural network that predicts the feasibility of a mixed-integer program from visual input for robot manipulation planning. Integrating learning into task and motion planning is challenging, since it is unclear how the scene and goals can be encoded as input to the learning algorithm in a way that enables to generalize over a variety of tasks in environments with changing numbers of objects and goals. To achieve this, we propose to encode the scene and the target object directly in the image space.","tags":["myself"],"title":"Deep Visual Heuristics: Learning Feasibility of Mixed-Integer Programs for Manipulation Planning","type":"publication"},{"authors":["Apostolos Axenopulos","Georgios Papadopoulos","Dimitrios Giakoumis","Ioannis Kostavelis","Alexis Papadimitriou Papadimitriou","Sara Sillaurren","Leire Bastida","Ozgur Oguz","Dirk Wollherr","Eugenio Garnica","Vasiliki Vouloutsi","Paul Verschure","Dimitrios Tzovaras","Petros Daras"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"bc9c11a60e95b1e92d8df9197f049091","permalink":"/publication/axenopulos-hybrid-2019/","publishdate":"2020-06-06T16:04:50.488935Z","relpermalink":"/publication/axenopulos-hybrid-2019/","section":"publication","summary":"In this paper, a novel hybrid human-robot recycling plant for electrical and electronic equipment is introduced. The proposed system will be developed in the context of the European research project HR-Recycler and its goal is to offer a hybrid collaboration environment for humans and robots. Through this collaboration, several currently manual, expensive, hazardous and time-consuming tasks of WEEE materials pre-processing will be substituted by automatic robotic-based procedures (categorization of electric/electronic devices, disassembling them, sorting of device components), before the materials enter the fine shredding machine. Although several solutions have been proposed for automation of recycling other types of waste (e.g. domestic), the industrial application case of WEEE recycling poses significant challenges and it is the first time, to the best of our knowledge, that a hybrid human-robot solution is proposed to address this problem.","tags":["myself"],"title":"A Hybrid Human-Robot Collaborative Environment for Recycling Electrical and Electronic Equipment","type":"publication"},{"authors":["Ozgur S. Oguz","Wolfgang Rampeltshammer","Sebastian Paillan","Dirk Wollherr"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"127cfbfd00d07fecdc2455a7bb74adfa","permalink":"/publication/oguz-ontology-2019/","publishdate":"2020-06-06T16:04:50.488505Z","relpermalink":"/publication/oguz-ontology-2019/","section":"publication","summary":"","tags":["myself"],"title":"An Ontology for Human-Human Interactions and Learning Interaction Behavior Policies","type":"publication"},{"authors":["Khoi Hoang Dinh","Ozgur S. Oguz","Mariam Elsayed","Dirk Wollherr"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"ff93ed520488c4f1f14f32d14417b4e1","permalink":"/publication/hoang-dinh-adaptation-2019/","publishdate":"2020-06-06T16:04:50.487787Z","relpermalink":"/publication/hoang-dinh-adaptation-2019/","section":"publication","summary":"In the context of human-robot collaboration in close proximity, safety and comfort are the two important aspects to achieve joint tasks efficiently. For safety, the robot must be able to avoid dynamic obstacles such as a human arm with high reliability. For comfort, the trajectories and avoidance behavior of the robot need to be predictable to the humans. Moreover, these two aspects might be different from person to person or from one task to another. This work presents a framework to generate predictable motions with dynamic obstacle avoidance for the robot interacting with the human by using policy improvement method. The trajectories are generated using Dynamic Motion Primitives with an additional potential field term that penalizes trajectories that may lead to collisions with obstacles. Furthermore, human movements are predicted using a data-driven approach for proactive avoidance. A cost function is defined which measures different aspects that affect the comfort and predictability of human co-workers (e.g. human response time, joint jerk). This cost function is then minimized during human-robot interaction by the means of policy improvement through black-box optimization to generate robot trajectories that adapt to human preferences and avoid obstacles. User studies are performed to evaluate the trust and comfort of human co-workers when working with the robot. In addition, the studies are also extended to various scenarios and different users to analyze the task transferability. This improves the learning performance when switching to a new task or the robot has to adapt to a different co-worker.","tags":["myself"],"title":"Adaptation and Transfer of Robot Motion Policies for Close Proximity Human-Robot Interaction","type":"publication"},{"authors":["Danny Driess","Ozgur S Oguz","Marc Toussaint"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d25740a9d6c789f6bdcb9a3a386352c4","permalink":"/publication/driess-hierarchical-2019/","publishdate":"2020-06-06T16:04:50.487338Z","relpermalink":"/publication/driess-hierarchical-2019/","section":"publication","summary":"In this work, we present a hierarchical approach to task and motion planning (TAMP) within an optimizationbased framework. Recent work on formulating TAMP as a logic enhanced nonlinear program has shown remarkable capabilities. However, scaling this approach to domains with many discrete decisions or longer horizons implies a computational bottleneck. To overcome this, we introduce hierarchies within this framework, where on coarser levels a problem with less discrete decisions is solved. Formally, the hierarchies are deÔ¨Åned in a way that the resulting nonlinear programs on coarser hierarchy levels are lower bounds on the Ô¨Åner hierarchies. We demonstrate the generality of the approach for both a bi-manual manipulation task and a mobile manipulation scenario which includes a ‚Äúworm‚Äù like walking robot.","tags":["myself"],"title":"Hierarchical Task and Motion Planning using Logic-Geometric Programming (HLGP)","type":"publication"},{"authors":["Ozgur S. Oguz","Zhehua Zhou","Stefan Glasauer","Dirk Wollherr"],"categories":null,"content":"","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"47821644d34e4cae0b6c7775bae4a80d","permalink":"/publication/oguz-inverse-2018/","publishdate":"2020-06-06T16:04:50.485403Z","relpermalink":"/publication/oguz-inverse-2018/","section":"publication","summary":"","tags":["myself"],"title":"An Inverse Optimal Control Approach to Explain Human Arm Reaching Control Based on Multiple Internal Models","type":"publication"},{"authors":["Ozgur S. Oguz","Ben M. Pfirrmann","Mingpan Guo","Dirk Wollherr"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"fe419b082fcefe7a0221d0157a5dbfd2","permalink":"/publication/oguz-learning-2018/","publishdate":"2020-06-06T16:04:50.488007Z","relpermalink":"/publication/oguz-learning-2018/","section":"publication","summary":"A key problem in robotics is enabling an autonomous agent to perform human-like arm movements in close proximity to another human. However, modeling the human decision and control process of the movement during dyadic interaction presents a challenge. Although, most prior approaches rely on multicomponent robot motion planning architectures, we use data of two humans performing interfering arm reaching movements to extract and transfer interaction behavior control skill to a robotic agent. A recurrent neural network-based framework is constructed to learn a policy that computes control signals for a robot end effector in order to replace one human. The learned policy is benchmarked against unseen interaction data and a state-of-the-art learning from demonstration framework in simulated scenarios. We compare several architectures and investigate a new activation function of three stacked tanh(). The results show that the proposed framework successfully learns a policy to imitate human movement behavior control during dyadic interaction. The policy is transferred to a real robot and its feasibility for close-proximity human-robot interaction is shown.","tags":["myself"],"title":"Learning Hand Movement Interaction Control Using RNNs: From HHI to HRI","type":"publication"},{"authors":["Ozgur S. Oguz","Zhehua Zhou","Dirk Wollherr"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"4ee852b6c2e37dca28406ef6438b897d","permalink":"/publication/oguz-hybrid-2018/","publishdate":"2020-06-06T16:04:50.485884Z","relpermalink":"/publication/oguz-hybrid-2018/","section":"publication","summary":"Robots collaborating naturally with a human partner in a confined workspace need to understand and predict human motions. For understanding, a model-based approach is required as the human motor control system relies on the biomechanical properties to control and execute actions. The model-based control models explain human motions descriptively, which in turn enables predicting and analyzing human movement behaviors. In motor control, reaching motions are framed as an optimization problem. However, different optimality criteria predict disparate motion behavior. Therefore, the inverse problem -- finding the optimality criterion from a given arm motion trajectory -- is not unique. This paper implements an inverse optimal control (IOC) approach to determine the combination of cost functions that governs a motion execution. The results indicate that reaching motions depend on a trade-off between kinematics and dynamics related cost functions. However, the computational efficiency is not sufficient for online prediction to be utilized for HRI. In order to predict human reaching motions with high efficiency and accuracy, we combine the IOC approach with a probabilistic movement primitives formulation. This hybrid model allows an online-capable prediction while taking into account motor variability, and the interpersonal differences. The proposed framework affords a descriptive and a generative model of human reaching motions which can be effectively utilized online for human-in-the-loop robot control and task execution.","tags":["myself"],"title":"A Hybrid Framework for Understanding and Predicting Human Reaching Motions","type":"publication"},{"authors":["Ozgur S. Oguz","Ben M. Pfirrmann","Dirk Wollherr"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"a3844551a9f44ed785510e2c4f6549e2","permalink":"/publication/oguz-ws-learning-2018/","publishdate":"2020-06-06T16:04:50.488756Z","relpermalink":"/publication/oguz-ws-learning-2018/","section":"publication","summary":"","tags":null,"title":"Learning Hand Movement Interaction Control Using RNNs: From HHI to HRI","type":"publication"},{"authors":["Ozgur S. Oguz","Omer C. Sari","Khoi H. Dinh","Dirk Wollherr"],"categories":null,"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501545600,"objectID":"dc2946cdda2df3cc95c6688601d37e51","permalink":"/publication/oguz-progressive-2017/","publishdate":"2020-06-06T16:04:50.485639Z","relpermalink":"/publication/oguz-progressive-2017/","section":"publication","summary":"This paper introduces a new approach to optimal online motion planning for human-robot interaction scenarios. For a safe, comfortable, and efficient interaction between human and robot working in close proximity, robot motion has to be agile and perceived as natural by the human partner. The robot has to be aware of its environment, including human motions, in order to proactively take actions while ensuring safety, and task fulfillment. Human motion prediction constitutes the fundamental perception input for the motion planner. The prediction system, which is based on probabilistic movement primitives, generates a prediction of human motion as a trajectory distribution learned in an offline phase. The proposed stochastic optimization-based planning algorithm then progressively finds feasible optimization parameters to replan the motion online that ensures collision avoidance while minimizing the task-related trajectory cost. Our simulation results show that the proposed approach produces collision-free trajectories while still reaching the goal successfully. We also highlight the performance of our planner in comparison to previous methods in stochastic motion planning.","tags":["myself"],"title":"Progressive stochastic motion planning for human-robot interaction","type":"publication"},{"authors":["Volker Gabler","Tim Stahl","Gerold Huber","Ozgur Oguz","Dirk Wollherr"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"8f80a20509b26f005689bfb0575e83df","permalink":"/publication/gabler-game-theoretic-2017/","publishdate":"2020-06-06T16:04:50.484426Z","relpermalink":"/publication/gabler-game-theoretic-2017/","section":"publication","summary":"With the integration of Human-Robot Collaboration (HRC) in industrial assembly scenarios, robot systems face numerous challenges. In contrast to classic robot systems which follow a pre-programmed and Ô¨Åxed sequence of actions, an interaction scenario with humans in the loop requires mutual adaptation. In this paper a framework based on game theory is presented that allows robots to choose appropriate actions with respect to the action of human coworkers when collaborating in close proximity. The proposed framework models HRC scenarios as iterative games and selects action-strategies for the Human-Robot Team (HRT) by Ô¨Ånding the Nash-Equilibria (NEs) of these games. In contrast to most common approaches, our proposed HRC-game treats the decision-making behavior equally for all agents involved. Therefore, the concept of game theory is applied to evaluate the mutual interference of all actions on the HRT to obtain pareto-optimal NEs, i.e. team-optimal action-allocations. The general framework of the proposed HRC-game is realized on an interactive pick-andplace scenario in close proximity. This exemplary HRC-game is tested in a human subject experiment of a KUKA LWR 4+ robot and a human coworker assembling toy-bricks in close proximity. The experimental measurements and statistically signiÔ¨Åcant improvements in the subjective feedback hold as a proof-of-concept of the proposed HRC-game model.","tags":["myself"],"title":"A game-theoretic approach for adaptive action selection in close proximity human-robot-collaboration","type":"publication"},{"authors":["Ozgur S. Oguz","Volker Gabler","Gerold Huber","Zhehua Zhou","Dirk Wollherr"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"646bd1bb3df143b4ffce825d1056e1d9","permalink":"/publication/kulic-hybrid-2017/","publishdate":"2020-06-06T16:04:50.487553Z","relpermalink":"/publication/kulic-hybrid-2017/","section":"publication","summary":"We present a Human-Robot-Collaboration (HRC) framework consisting of a hybrid human motion prediction approach together with a game theoretical action selection. In essence, the robot is required to predict the motions of the human co-worker, and to proactively decide on its actions. For our prediction framework, model-based human motion trajectories are learned by data-driven methods for eÔ¨Écient trajectory rollouts in which obstacles are also considered. We provide the reliability analysis of human trajectory predictions within a human-robot collaboration experimental setup. The HRC scenario is modeled as an iterative game to select the actions for the Human-Robot-Team (HRT) by Ô¨Ånding the Nash Equilibrium of the game. Experimental evaluation shows how the proposed prediction approach can be successfully integrated into a game theory based action selection framework.","tags":null,"title":"Hybrid Human Motion Prediction for Action Selection Within Human-Robot Collaboration","type":"publication"},{"authors":["Ozgur S. Oguz","Volker Gabler","Gerold Huber","Zhehua Zhou","Dirk Wollherr"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"b7c60939e7b7ce509c6be7f9418e062f","permalink":"/publication/oguz-hybrid-2017/","publishdate":"2020-06-06T15:35:39.462212Z","relpermalink":"/publication/oguz-hybrid-2017/","section":"publication","summary":"We present a Human-Robot-Collaboration (HRC) framework consisting of a hybrid human motion prediction approach together with a game theoretical action selection. In essence, the robot is required to predict the motions of the human co-worker, and to proactively decide on its actions. For our prediction framework, model-based human motion trajectories are learned by data-driven methods for eÔ¨Écient trajectory rollouts in which obstacles are also considered. We provide the reliability analysis of human trajectory predictions within a human-robot collaboration experimental setup. The HRC scenario is modeled as an iterative game to select the actions for the Human-Robot-Team (HRT) by Ô¨Ånding the Nash Equilibrium of the game. Experimental evaluation shows how the proposed prediction approach can be successfully integrated into a game theory based action selection framework.","tags":null,"title":"Hybrid Human Motion Prediction for Action Selection Within Human-Robot Collaboration","type":"publication"},{"authors":["Khoi Hoang Dinh","Ozgur Oguz","Gerold Huber","Volker Gabler","Dirk Wollherr"],"categories":null,"content":"","date":1433116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433116800,"objectID":"fcea5dc65c0930bb214767755ec77e3f","permalink":"/publication/dinh-approach-2015/","publishdate":"2020-06-06T16:04:50.485143Z","relpermalink":"/publication/dinh-approach-2015/","section":"publication","summary":"Within Human-Robot Collaboration (HRC) safety is one key-issue that has to be guaranteed at any time during joint collaboration. Collisions in a shared workspace of a Human-Robot-Team (HRT) must be prevented. In addition, the comfort of the collaboration behavior should be provided. Facing these challenges, a robot has to be able to detect critical states at an early stage on the one hand and should react to them within a very short time span on the other hand. In this paper a collision avoidance algorithm using compliance control that guarantees a fast reaction to dynamic obstacles, e.g. humans, without the need of high computational effort is outlined. To further improve the avoidance behavior of the robot, a human motion prediction algorithm based on the minimum-jerk model is integrated. In an experimental analysis of a case-study about collecting LEGO-bricks on a table with various subjects, the impact of the integration of human motion prediction on both the robot‚Äôs reaction time and human‚Äôs perception of the robot co-worker is studied. Finally, the comfort and acceptance of the robot colleague by the human collaborator is drawn out through an analysis of the subjective human feedback questionnaires.","tags":["myself"],"title":"An approach to integrate human motion prediction into local obstacle avoidance in close human-robot collaboration","type":"publication"},{"authors":["Ayse Kucukyilmaz","Salih Ozgur Oguz","Tevfik Metin Sezgin","Cagatay Basdogan"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"a66924bee4c3f32a080e267372deb04b","permalink":"/publication/peer-improving-2012/","publishdate":"2020-06-06T16:04:50.48492Z","relpermalink":"/publication/peer-improving-2012/","section":"publication","summary":"","tags":["myself"],"title":"Improving Human-Computer Cooperation Through Haptic Role Exchange and Negotiation","type":"publication"},{"authors":["S. Ozgur Oguz","Ayse Kucukyilmaz","Tevfik Metin Sezgin","Cagatay Basdogan"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"569c088eef586426032efe3684755b39","permalink":"/publication/oguz-supporting-2012/","publishdate":"2020-06-06T16:04:50.484691Z","relpermalink":"/publication/oguz-supporting-2012/","section":"publication","summary":"An active research goal for human-computer interaction is to allow humans to communicate with computers in an intuitive and natural fashion, especially in real-life interaction scenarios. One approach that has been advocated to achieve this has been to build computer systems with human-like qualities and capabilities. In this paper, we present insight on how human-computer interaction can be enriched by employing the computers with behavioral patterns that naturally appear in human-human negotiation scenarios. For this purpose, we introduce a two-party negotiation game specifically built for studying the effectiveness of haptic and audio-visual cues in conveying negotiation related behaviors. The game is centered around a real-time continuous two-party negotiation scenario based on the existing game-theory and negotiation literature. During the game, humans are confronted with a computer opponent, which can display different behaviors, such as concession, competition, and negotiation. Through a user study, we show that the behaviors that are associated with human negotiation can be incorporated into human-computer interaction, and the addition of haptic cues provides a statistically significant increase in the human-recognition accuracy of machine-displayed behaviors. In addition to aspects of conveying these negotiation-related behaviors, we also focus on and report game-theoretical aspects of the overall interaction experience. In particular, we show that, as reported in the game-theory literature, certain negotiation strategies such as tit-for-tat may generate maximum combined utility for the negotiating parties, providing an excellent balance between the energy spent by the user and the combined utility of the negotiating parties.","tags":["myself"],"title":"Supporting Negotiation Behavior with Haptics-Enabled Human-Computer Interfaces","type":"publication"},{"authors":["S. Ozgur Oguz","Ayse Kucukyilmaz","Tevfik Metin Sezgin","Cagatay Basdogan"],"categories":null,"content":"","date":1267401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1267401600,"objectID":"1141412518f9addd504efd15755ffcbd","permalink":"/publication/oguz-haptic-2010/","publishdate":"2020-06-06T16:04:50.483966Z","relpermalink":"/publication/oguz-haptic-2010/","section":"publication","summary":"We investigate how collaborative guidance can be realized in multimodal virtual environments for dynamic tasks involving motor control. Haptic guidance in our context can be deÔ¨Åned as any form of force/tactile feedback that the computer generates to help a user execute a task in a faster, more accurate, and subjectively more pleasing fashion. In particular, we are interested in determining guidance mechanisms that best facilitate task performance and arouse a natural sense of collaboration. We suggest that a haptic guidance system can be further improved if it is supplemented with a role exchange mechanism, which allows the computer to adjust the forces it applies to the user in response to his/her actions. Recent work on collaboration and role exchange presented new perspectives on deÔ¨Åning roles and interaction. However existing approaches mainly focus on relatively basic environments where the state of the system can be deÔ¨Åned with a few parameters. We designed and implemented a complex and highly dynamic multimodal game for testing our interaction model. Since the state space of our application is complex, role exchange needs to be implemented carefully. We deÔ¨Åned a novel negotiation process, which facilitates dynamic communication between the user and the computer, and realizes the exchange of roles using a three-state Ô¨Ånite state machine. Our preliminary results indicate that even though the negotiation and role exchange mechanism we adopted does not improve performance in every evaluation criteria, it introduces a more personal and humanlike interaction model.","tags":null,"title":"Haptic negotiation and role exchange for collaboration in virtual environments","type":"publication"}]